{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e9cc81a780fe47eea7f73bef087c9ab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab92234a4a6e4f32b47886423a383422",
       "IPY_MODEL_775c30cf2df8454e8ee0bdbf8dd6bf62",
       "IPY_MODEL_4007d330d96441d8b5a84f0826d57951"
      ],
      "layout": "IPY_MODEL_37b6d968833644669f4d6d634e9cde9c"
     }
    },
    "ab92234a4a6e4f32b47886423a383422": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c03069fe7d5d489e935d4dd52ac482c2",
      "placeholder": "​",
      "style": "IPY_MODEL_7d0fc50117474710bf282bc4b91a97c4",
      "value": "Parsing nodes: 100%"
     }
    },
    "775c30cf2df8454e8ee0bdbf8dd6bf62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37a682a9b4674d989f702df887580405",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2550cccb5d7c4c3e9c81bf0a1e3ac476",
      "value": 2
     }
    },
    "4007d330d96441d8b5a84f0826d57951": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd225432c234470b910ecc4e29e28d30",
      "placeholder": "​",
      "style": "IPY_MODEL_c3bb1e31eef643b3864d3bfa603e2d35",
      "value": " 2/2 [00:01&lt;00:00,  1.45it/s]"
     }
    },
    "37b6d968833644669f4d6d634e9cde9c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c03069fe7d5d489e935d4dd52ac482c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d0fc50117474710bf282bc4b91a97c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37a682a9b4674d989f702df887580405": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2550cccb5d7c4c3e9c81bf0a1e3ac476": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd225432c234470b910ecc4e29e28d30": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3bb1e31eef643b3864d3bfa603e2d35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[Linktext](https://)# Q&A on the content of a bunch of files\n",
    "Goal:\n",
    "- Read all files in a folder containing text (pdf, word, markdown, ...)\n",
    "- Ask questions on the content of the files\n",
    "- Avoid any answers based on information that is not in the source data"
   ],
   "metadata": {
    "id": "2mT5iJgUc-MQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install dependencies and setup environment"
   ],
   "metadata": {
    "id": "xOt-L_yidl-9"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUrEKj7irT1v",
    "outputId": "74ea1664-361a-4b2f-f404-26191a36699a",
    "ExecuteTime": {
     "end_time": "2024-06-04T09:25:43.952547Z",
     "start_time": "2024-06-04T09:25:39.108347Z"
    }
   },
   "source": [
    "!pip install -qU llama-index datasets openai transformers cohere pypdf Markdown docx2txt llama-index-readers-file\n",
    "# !pip install langchain langchainhub llama-index-llms-langchain\n",
    "!pip install llama-index-llms-ollama"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting llama-index-llms-ollama\r\n",
      "  Obtaining dependency information for llama-index-llms-ollama from https://files.pythonhosted.org/packages/4f/45/f37075b0b075c56d85c8a6868f4641bdc610e66bf6e056f7021713266be9/llama_index_llms_ollama-0.1.5-py3-none-any.whl.metadata\r\n",
      "  Downloading llama_index_llms_ollama-0.1.5-py3-none-any.whl.metadata (585 bytes)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-llms-ollama) (0.10.43)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.0.29)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.6.4)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.3.1)\r\n",
      "Requirement already satisfied: httpx in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.1.19)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.2.1)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.8.1)\r\n",
      "Requirement already satisfied: numpy in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.31.0)\r\n",
      "Requirement already satisfied: pandas in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.7.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.11.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.16.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.0.3)\r\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.7.0)\r\n",
      "Requirement already satisfied: anyio in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.3.0)\r\n",
      "Requirement already satisfied: certifi in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.5.15)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.26.18)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.21.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.2.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (23.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.18.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/tobiasschneider/Documents/Uni/Sommersemester 24/DataScience/Projects/DS-11/venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.16.0)\r\n",
      "Downloading llama_index_llms_ollama-0.1.5-py3-none-any.whl (3.6 kB)\r\n",
      "Installing collected packages: llama-index-llms-ollama\r\n",
      "Successfully installed llama-index-llms-ollama-0.1.5\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup API-Key for OpenAI"
   ],
   "metadata": {
    "id": "uESnBkWxRMyX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''  # platform.openai.com"
   ],
   "metadata": {
    "id": "42MNdLA6rnRm",
    "ExecuteTime": {
     "end_time": "2024-06-04T09:29:10.745734Z",
     "start_time": "2024-06-04T09:29:10.740077Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load documents\n",
    "Documents are a container provides by LlamaIndex around the actual source files.\n",
    "We read all documents uploaded to the colab instance using the SimpleDirectoryReader.\n"
   ],
   "metadata": {
    "id": "3hg6nqM6dytF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "filename_fn = lambda filename: {\"file_name\": filename}\n",
    "documents = SimpleDirectoryReader(\"../data/pdf\", file_metadata=filename_fn).load_data()\n",
    "\n",
    "print(documents[0])\n",
    "len(documents)"
   ],
   "metadata": {
    "id": "U3BHdfDHranT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d9161445-a6e5-43b1-c2fa-5028f83e30ea",
    "ExecuteTime": {
     "end_time": "2024-06-04T09:26:16.774838Z",
     "start_time": "2024-06-04T09:26:14.625385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 13283e98-a2ec-4494-96b7-87dfb839fe16\n",
      "Text: Portable Data Recorder   HMG 4000       Operating Manual\n",
      "(Translation of o riginal instructions )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parsing documents and creating embeddings\n",
    "This process involves setting up a TextSplitter to chunk up the source data, configuring an EmbeddingModel to define the desired embedding, and creating a GPTVectorStore to convert the documents into embeddings."
   ],
   "metadata": {
    "id": "QNUR_fiCh9cR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor, KeywordExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# Define metadata extractors\n",
    "transformations = [\n",
    "    SentenceSplitter(),\n",
    "    #TitleExtractor(nodes=5),\n",
    "    #KeywordExtractor(keywords=10),\n",
    "    #OpenAIEmbedding(model='text-embedding-3-large', embed_batch_size=100)\n",
    "]\n",
    "\n",
    "# Create ingestion pipeline\n",
    "pipeline = IngestionPipeline(transformations=transformations)\n",
    "\n",
    "nodes = pipeline.run(\n",
    "    documents=documents,\n",
    "    show_progress=True\n",
    "    )\n",
    "\n",
    "print(nodes[0].metadata)"
   ],
   "metadata": {
    "id": "EM9wUg2TJW6B",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "e9cc81a780fe47eea7f73bef087c9ab3",
      "ab92234a4a6e4f32b47886423a383422",
      "775c30cf2df8454e8ee0bdbf8dd6bf62",
      "4007d330d96441d8b5a84f0826d57951",
      "37b6d968833644669f4d6d634e9cde9c",
      "c03069fe7d5d489e935d4dd52ac482c2",
      "7d0fc50117474710bf282bc4b91a97c4",
      "37a682a9b4674d989f702df887580405",
      "2550cccb5d7c4c3e9c81bf0a1e3ac476",
      "cd225432c234470b910ecc4e29e28d30",
      "c3bb1e31eef643b3864d3bfa603e2d35"
     ]
    },
    "outputId": "6f9d3363-7490-4e01-fdee-32ae5a7afc33"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Parsing nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9cc81a780fe47eea7f73bef087c9ab3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'file_name': '/content/converted.docx'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding(model='text-embedding-3-large', embed_batch_size=100)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=embed_model\n",
    ")"
   ],
   "metadata": {
    "id": "pGsFqDLwr6GM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "s1wDgjodgqoF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "query_engine = index.as_query_engine()\n",
    "\n",
    "res = query_engine.query(\"How to init and get data from analog inputs on TTC 500 in C ?\")\n",
    "print(res)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2-jHqq7BVBG",
    "outputId": "f1dfe2a7-0b96-473b-92ca-d84f2e437b09"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "To initialize and retrieve data from analog inputs on TTC 500 in C, you can follow these steps:\n",
      "\n",
      "1. Call the function `IO_Driver_Init()` as the first function during initialization to initialize the driver.\n",
      "2. Use the function `IO_ADC_ChannelInit()` to set up the desired ADC channel with parameters such as channel number, input type, input range, and pull-up/down configuration.\n",
      "3. Periodically call the task function, where you can include calls to driver task functions.\n",
      "4. Within the task function, use `IO_ADC_Get()` to retrieve the raw ADC value from the desired ADC channel.\n",
      "5. Convert the raw ADC value to temperature in degrees Celsius using the function `IO_ADC_BoardTempSbyte()`.\n",
      "6. Handle any errors or safety callbacks as needed based on the application requirements.\n",
      "\n",
      "By following these steps, you can successfully initialize and obtain data from analog inputs on TTC 500 in C.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Querying"
   ],
   "metadata": {
    "id": "muO-hn3Fjmoj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "#chat_engine = index.as_chat_engine()\n",
    "\n",
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))\n",
    "\n",
    "\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)\n",
    "\n",
    "from langchain import hub\n",
    "langchain_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "from llama_index.core.prompts import LangchainPromptTemplate FewShotPromptTemplate\n",
    "\n",
    "lc_prompt_tmpl = LangchainPromptTemplate(\n",
    "    template=langchain_prompt,\n",
    "    template_var_mappings={\"query_str\": \"question\", \"context_str\": \"context\"},\n",
    ")\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": lc_prompt_tmpl}\n",
    ")\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)\n",
    "#res = query_engine.chat(\"Geb mir eine Zusammenfassung des -Evaluation- Kapitel\")\n",
    "res = query_engine.query(\"Wie sah die Aufnahmeprüfung zur Volksschule aus?\")\n",
    "print(res)\n",
    "#res = query_engine.query(\"Welches State Management Nutzt das Flutter Frontend und in welcher Beziehung steht es zur Schichten-Architektur?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "srr6IiKjsxtq",
    "outputId": "a7d60949-1828-4583-c55b-b26475151357"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "<br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "<br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input_variables=['context', 'question'] metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "<br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "<br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Die Aufnahmeprüfung zur Volksschule bestand aus einem Diktat, einer Matheaufgabe und einem Aufsatz. Arbeiterkinder mussten einen großen Schritt machen, um sich überhaupt anzumelden und die Prüfung zu bestehen. Die Schulkarriere war für viele eine Herausforderung, da die meisten Schüler auf dem Weg zum Abitur scheiterten.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Query-Engines can be customized with custom node_postprocessors and retrievers.\n",
    "Also the response-mode defines how the llm"
   ],
   "metadata": {
    "id": "KpyMny7akUHU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "custom_query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    "    response_mode=\"tree_summarize\"\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\"Geb mir eine Zusammenfassung des -Evaluation- Kapitel\")\n",
    "print(response)"
   ],
   "metadata": {
    "id": "Rycza4pMuPnh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6869c341-1e00-43b0-9562-39fa8d04356e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Das Evaluation-Kapitel befasst sich mit der Bewertung der entwickelten Lösung anhand verschiedener Merkmale. Zunächst wird die funktionale Vollständigkeit betrachtet, bei der überprüft wird, ob alle zuvor definierten Ziele erreicht wurden. Es wird festgestellt, dass der Anmelde- und Registrierungsprozess nur im xCollect Frontend verfügbar ist und neue Nutzer in der Appwrite Web-Oberfläche angelegt werden müssen. Das Anlegen und Löschen von Kontext-Analysen ist in der Session-Übersicht von xCollect möglich, jedoch fehlt noch die Funktionalität des automatischen Löschens von Kontext-Analysen. Das Hinzufügen und Synchronisieren von Medien ist enthalten, ebenso wie das gleichzeitige Aufnehmen von Audio-Aufnahmen und Videos. Das Hinzufügen von externen Fotos und Videos ist sowohl in der Desktop- als auch in der Mobile-Anwendung möglich. Daten können exportiert werden, wobei in der Desktop-Anwendung der File Explorer bzw. Finder genutzt wird und in der Mobile-Version die Foto-Galerie. Der Offline-Modus ermöglicht das Erstellen von neuen MediaItems ohne Internetverbindung, jedoch können diese nicht bearbeitet oder gelöscht werden und es können keine Sessions angelegt, bearbeitet oder gelöscht werden, während der Nutzer offline ist.\n"
     ]
    }
   ]
  }
 ]
}
